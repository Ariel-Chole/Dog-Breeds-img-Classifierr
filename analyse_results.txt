After running the check_images.py gives the following results based on each CNN model architecture,
  *** Results Summary for CNN Model Architecture VGG ***
N Images            :   4
N Dog Images        :   2
N Not-Dog Images    :   2
 
pct_match: 100.0
pct_correct_dogs: 100.0
pct_correct_breed: 100.0
pct_correct_notdogs: 100.0

*** Results Summary for CNN Model Architecture ALEXNET ***
N Images            :   4
N Dog Images        :   2
N Not-Dog Images    :   2
 
pct_match: 100.0
pct_correct_dogs: 100.0
pct_correct_breed: 100.0
pct_correct_notdogs: 100.0

*** Results Summary for CNN Model Architecture RESNET ***
N Images            :   4
N Dog Images        :   2
N Not-Dog Images    :   2
 
pct_match: 100.0
pct_correct_dogs: 100.0
pct_correct_breed: 100.0
pct_correct_notdogs: 100.0


Then I compared these results with the results from running run_models_batch.sh for
N Images            :  40
N Dog Images        :  30
N Not-Dog Images    :  10

After comparing the resuls, I realized that even though all three models give 100% of correct classification on uploaded pictures, for pet images they gives
For "CNN Model Architecture VGG"
pct_match: 87.5
pct_correct_dogs: 100.0
pct_correct_breed: 93.33333333333333
pct_correct_notdogs: 100.0

For "CNN Model Architecture ALEXNET"
pct_match: 75.0
pct_correct_dogs: 100.0
pct_correct_breed: 80.0
pct_correct_notdogs: 100.0

For"CNN Model Architecture RESNET"
pct_match: 82.5
pct_correct_dogs: 100.0
pct_correct_breed: 90.0
pct_correct_notdogs: 90.0

By viewing the result, we can easily know that VGG is the best architecture model for classification of pet images compared to others. Therefore, when we run run_models_batch.sh, classification percentage, especially for pct_match and pct_correct_breed, decrease and all of them can classify whether it is a dog with 100%. 

